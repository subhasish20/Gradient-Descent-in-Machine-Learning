# 🌈 Gradient Descent in Machine Learning  

🚀 **A practical exploration of gradient descent and its optimization variants implemented from scratch in Python.**  



## 📘 Overview  

Gradient Descent is one of the fundamental optimization techniques used in machine learning and deep learning.  
This project demonstrates **how gradient descent works step by step**, helping learners visualize the process of minimizing a cost function through iterative updates.  

You’ll find clean, well-commented Python implementations of basic and advanced variants of gradient descent, designed for educational and experimental purposes.  

---

## 🧩 Features  

✨ **From Scratch Implementations** – Learn the mechanics behind gradient descent without relying on heavy ML frameworks.  
⚙️ **Multiple Variants** – Explore Batch, Stochastic, and Mini-Batch gradient descent approaches.  
📈 **Visualization Support** – Plot the descent process to see how parameters evolve over iterations.  
📊 **Detailed Comments** – Every section is explained to ease understanding for beginners.  

---



## 🧠 Core Concepts  

- **Cost Function (Loss)** – The measure of error between predicted and true values.  
- **Learning Rate (α)** – The step size controlling how quickly we update parameters.  
- **Convergence** – Iteratively moving toward the minimum of the cost function.  
- **Variants** – Trade-offs between computation time and stability.  

---

## ⚡ Installation  

Get started by cloning the repo and installing dependencies:  

```bash
git clone https://github.com/subhasish20/Gradient-Descent-in-Machine-Learning.git
cd Gradient-Descent-in-Machine-Learning
pip install -r requirements.txt
```

---

## 🧑‍💻 Usage  

Run the main script to see gradient descent in action:  

```bash
python src/gradient_descent.py
```

Or open the notebooks to interactively visualize the learning process:  

```bash
jupyter notebook notebooks/
```

---

## 📊 Example Output  

Expect an animated cost reduction curve and trajectory plots demonstrating convergence of parameters — perfect for gaining intuition about optimization dynamics.  

---

## 💡 Learning Outcomes  

By exploring this repo, you’ll:  
- Understand gradient descent intuition and math.  
- Learn practical implementation details.  
- Get comfortable with plotting and interpreting optimization behavior.  

---


## 🧾 License  

This project is released under the **MIT License**. Use it freely for learning and teaching.  

---

